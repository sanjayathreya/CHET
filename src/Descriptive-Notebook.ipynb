{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjxMusQ9UBQ22mSCoLCfqZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjayathreya/cs598dl4h-project/blob/main/src/Descriptive-Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Reproducibility summary**\n",
        "\n",
        "This notebook describes the methods followed by the paper **Chang Lu, Tian Han, and Yue Ning. 2021a. Context- aware health event prediction via transition functions on dynamic disease graphs(Chet). ArXiv, abs/2112.05195**\n",
        "\n",
        "1.   Claim 1: For heart failure prediction task, Chet outperforms the baseline models based on metrics such as AUC and F1-scores on MIMIC III and MIMIC IV data sets.\n",
        "\n",
        "2. Claim 2: For diagnosis prediction task, Chet outperforms the baseline models based on MIMIC III and MIMIC IV data sets. The authors compare w-F1 is a weighted sum of F1 scores for all medical codes and R@k which is an average ratio of desired medical codes in top k predictions by the total number of\n",
        "desired medical codes in each visit.\n",
        "\n",
        "To verify these claims, we reproduced these results MIMIC III- carevue (Johnson et al., 2022) which excludes overlap of patients in MIMIC IV, and MIMIC IV (Johnson et al., 2023). Additionally, we investigated the effectiveness of the model under different experimental setups such comparing performance of model by changing the number of training epochs, using a different pre-processing\n",
        "method to extract data, ablation studies that do not include dynamic graph and transition functions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9lAd4XW2mMUM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6yvXt0LbmLl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/sanjayathreya/cs598dl4h-project\n",
        "!mv /content/cs598dl4h-project /content/CHET"
      ],
      "metadata": {
        "id": "b4s6ws3xmOw3",
        "outputId": "5844737b-954d-401a-cc21-2cb64b249daf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'cs598dl4h-project' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Copy the files paitients.csv, admissions.csv and diagnoses_icd.csv to mimic3\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# !mkdir /content/CHET/data/mimic3/raw/\n",
        "# !mkdir /content/CHET/data/mimic4/raw/\n",
        "!cp -a /content/drive/MyDrive/CHET/data/mimic3/raw/ /content/CHET/data/mimic3/\n",
        "!cp -a /content/drive/MyDrive/CHET/data/mimic4/raw/ /content/CHET/data/mimic4/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rybth0xtlxuI",
        "outputId": "8b203ad3-bcb6-4e18-ff93-835c7877abfb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/CHET/"
      ],
      "metadata": {
        "id": "LX5dtYwD0a5y",
        "outputId": "d088d082-642f-4825-b883-59da788f9a05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CHET\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "M8Ox1JXkVQ8z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b63a4238-b775-4ca3-8d1a-e21edb4d01b1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.5.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (8.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2022.7.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (1.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (3.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (0.15.1+cu118)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (4.5.0)\n",
            "Collecting pyhealth\n",
            "  Downloading pyhealth-1.1.3-py2.py3-none-any.whl (113 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.8/113.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 11)) (3.12.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 11)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 11)) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 11)) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 11)) (2.0.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->-r requirements.txt (line 11)) (16.0.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->-r requirements.txt (line 11)) (3.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 13)) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pyhealth->-r requirements.txt (line 15)) (4.65.0)\n",
            "Collecting rdkit>=2022.03.4\n",
            "  Downloading rdkit-2023.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 11)) (2.1.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 13)) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 13)) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 13)) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 13)) (2022.12.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 11)) (1.3.0)\n",
            "Installing collected packages: rdkit, pyhealth\n",
            "Successfully installed pyhealth-1.1.3 rdkit-2023.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/CHET/src\n",
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRowZYrvVTl0",
        "outputId": "e3988552-b99b-460c-b031-57aa502d1ab2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CHET\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pyhealth.medcode import CrossMap\n",
        "from pyhealth.datasets import MIMIC4Dataset,MIMIC3Dataset\n",
        "from pyhealth.medcode import InnerMap\n",
        "from pyhealth.datasets.utils import flatten_list\n",
        "from pyhealth.tokenizer import Tokenizer\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "icd9cm = InnerMap.load(\"ICD9CM\")\n",
        "data_path = 'data'"
      ],
      "metadata": {
        "id": "m-rsPuT7VXMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/CHET/ICD10CM_to_ICD9CM.csv /root/.cache/pyhealth/medcode"
      ],
      "metadata": {
        "id": "m136Ymr_O9GZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_parsed_datasets(patient_dict, tablename):\n",
        "  \"\"\"Do something.\n",
        "\n",
        "  Paragraph 1.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  argument_name : Type\n",
        "      description ending with a period.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  Type\n",
        "      description ending with a period.\n",
        "  \"\"\"\n",
        "  del_pid = {}\n",
        "  patient_admission = OrderedDict()\n",
        "  admission_codes = OrderedDict()\n",
        "\n",
        "  for pid, values in patient_dict.items():\n",
        "    patient = patient_dict[pid]\n",
        "    visit_dict = patient.visits\n",
        "    # we parse patients who have greater than 2 visits\n",
        "    if(len(visit_dict) >=2):\n",
        "      admissions = []\n",
        "      for visit_key, visit_values in visit_dict.items():\n",
        "        diagnoses = visit_values.get_code_list(table=tablename)\n",
        "        diagnoses_std = [icd9cm.standardize(code) for code in diagnoses]\n",
        "        admissions.append({'adm_id': visit_key, 'adm_time': visit_values.encounter_time})\n",
        "        admission_codes[visit_key] = diagnoses_std\n",
        "\n",
        "        # if there is a diagnose code with no mapping then drop the patient and \n",
        "        counter = 0\n",
        "        counter = sum([counter+1 for diagnoses in diagnoses_std if diagnoses =='' or diagnoses =='NoDx'])\n",
        "        if (len(diagnoses) == 0 or counter !=0 ):\n",
        "          del_pid[pid] = pid\n",
        "      patient_admission[pid] = sorted(admissions, key=lambda admission: admission['adm_time'])\n",
        "\n",
        "  for pid in del_pid.keys():\n",
        "    patient = patient_dict[pid]\n",
        "    visit_dict = patient.visits\n",
        "    del patient_admission[pid]\n",
        "    for visit_key, visit_values in visit_dict.items():\n",
        "      del admission_codes[visit_key]\n",
        "  \n",
        "  return patient_admission,admission_codes"
      ],
      "metadata": {
        "id": "w3s6T0gMOMqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stats( patient_admission, admission_codes):\n",
        "  \"\"\"Do something.\n",
        "\n",
        "  Paragraph 1.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  argument_name : Type\n",
        "      description ending with a period.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  Type\n",
        "      description ending with a period.\n",
        "  \"\"\"\n",
        "  patient_num = len(patient_admission)\n",
        "  max_admission_num = max([len(admissions) for admissions in patient_admission.values()])\n",
        "  avg_admission_num = sum([len(admissions) for admissions in patient_admission.values()]) / patient_num\n",
        "  max_visit_code_num = max([len(codes) for codes in admission_codes.values()])\n",
        "  avg_visit_code_num = sum([len(codes) for codes in admission_codes.values()]) / len(admission_codes)\n",
        "  print('patient num: %d' % patient_num)\n",
        "  print('max admission num: %d' % max_admission_num)\n",
        "  print('mean admission num: %.2f' % avg_admission_num)\n",
        "  print('max code num in an admission: %d' % max_visit_code_num)\n",
        "  print('mean code num in an admission: %.2f' % avg_visit_code_num)\n",
        "\n",
        "  return None"
      ],
      "metadata": {
        "id": "Nn1lO5hfmHOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_parsed_files(parsed_path, **kwargs):\n",
        "  \"\"\"Do something.\n",
        "\n",
        "  Paragraph 1.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  argument_name : Type\n",
        "      description ending with a period.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  Type\n",
        "      description ending with a period.\n",
        "  \"\"\"\n",
        "  if not os.path.exists(parsed_path):\n",
        "    os.makedirs(parsed_path)\n",
        "  for key, value in kwargs.items():\n",
        "    name = key+'.pkl'\n",
        "    pickle.dump(value, open(os.path.join(parsed_path, name), 'wb'))\n",
        "    print(f'saved {key} data ...')"
      ],
      "metadata": {
        "id": "0otQioEJmzkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mimic3_ds = MIMIC3Dataset(\n",
        "    root=\"data/mimic3/raw\",\n",
        "    tables=[\"DIAGNOSES_ICD\"]\n",
        ")\n",
        "dataset = 'mimic3'  # mimic3, eicu, or mimic4\n",
        "dataset_path = os.path.join(data_path,dataset)\n",
        "parsed_path = os.path.join(dataset_path, 'parsed')\n",
        "\n",
        "patient_dict = mimic3_ds.patients\n",
        "patient_admission,admission_codes = create_parsed_datasets(patient_dict, \"DIAGNOSES_ICD\")\n",
        "get_stats(patient_admission,admission_codes)\n",
        "save_parsed_files (parsed_path, patient_admission = patient_admission , admission_codes = admission_codes )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpSUyQrTmbB4",
        "outputId": "c696fccb-e643-4bc3-c780-bec6258c2f54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Parsing PATIENTS and ADMISSIONS: 100%|██████████| 23692/23692 [00:37<00:00, 637.81it/s]\n",
            "Parsing DIAGNOSES_ICD: 100%|██████████| 26830/26830 [00:03<00:00, 7451.56it/s]\n",
            "Mapping codes: 100%|██████████| 23692/23692 [00:00<00:00, 118674.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "patient num: 2169\n",
            "max admission num: 23\n",
            "mean admission num: 2.45\n",
            "max code num in an admission: 39\n",
            "mean code num in an admission: 10.70\n",
            "saved patient_admission data ...\n",
            "saved admission_codes data ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mimic4_ds = MIMIC4Dataset(\n",
        "    root=\"data/mimic4/raw\",\n",
        "    tables=[\"diagnoses_icd\"],\n",
        "    code_mapping={\"ICD10CM\": \"ICD9CM\"},\n",
        ")\n",
        "dataset = 'mimic4' \n",
        "dataset_path = os.path.join(data_path,dataset)\n",
        "parsed_path = os.path.join(dataset_path, 'parsed')\n",
        "patient_dict = mimic4_ds.patients\n",
        "patient_admission,admission_codes = create_parsed_datasets(patient_dict, \"diagnoses_icd\")\n",
        "get_stats(patient_admission,admission_codes)"
      ],
      "metadata": {
        "id": "77yrMFzZa27n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30f67484-f249-4c6c-9089-13782a1d8999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "patient num: 55875\n",
            "max admission num: 95\n",
            "mean admission num: 3.69\n",
            "max code num in an admission: 39\n",
            "mean code num in an admission: 9.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_samples(sample_num, seed, patient_admission, admission_codes):\n",
        "  \"\"\"Do something.\n",
        "\n",
        "  Paragraph 1.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  argument_name : Type\n",
        "      description ending with a period.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  Type\n",
        "      description ending with a period.\n",
        "  \"\"\"       \n",
        "  np.random.seed(seed)\n",
        "  keys = list(patient_admission.keys())\n",
        "  selected_pids = np.random.choice(keys, sample_num, False)\n",
        "  patient_admission_sample = {pid: patient_admission[pid] for pid in selected_pids}\n",
        "  admission_codes_sample = dict()\n",
        "  for admissions in patient_admission_sample.values():\n",
        "      for admission in admissions:\n",
        "          adm_id = admission['adm_id']\n",
        "          admission_codes_sample[adm_id] = admission_codes[adm_id]\n",
        "  return patient_admission_sample, admission_codes_sample"
      ],
      "metadata": {
        "id": "lwWYkS21o0Xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seeds = [6669, 1000, 1050, 2052, 3000]\n",
        "sample_num = 10000\n",
        "for idx, seed in enumerate(seeds):\n",
        "  patient_admission_sample, admission_codes_sample = generate_samples(sample_num, seed, patient_admission, admission_codes)\n",
        "  parsed_path_sample = os.path.join(parsed_path,str(idx))\n",
        "  save_parsed_files(parsed_path_sample, patient_admission = patient_admission_sample , admission_codes = admission_codes_sample )\n",
        "  get_stats(patient_admission_sample,admission_codes_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ur0LNyyiC8Qj",
        "outputId": "288f7502-5d86-405d-89b0-536e20ca6fce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saving parsed data ...\n",
            "saved patient_admission data ...\n",
            "saved admission_codes data ...\n",
            "patient num: 10000\n",
            "max admission num: 64\n",
            "mean admission num: 3.71\n",
            "max code num in an admission: 39\n",
            "mean code num in an admission: 9.29\n",
            "saving parsed data ...\n",
            "saved patient_admission data ...\n",
            "saved admission_codes data ...\n",
            "patient num: 10000\n",
            "max admission num: 77\n",
            "mean admission num: 3.68\n",
            "max code num in an admission: 39\n",
            "mean code num in an admission: 9.07\n",
            "saving parsed data ...\n",
            "saved patient_admission data ...\n",
            "saved admission_codes data ...\n",
            "patient num: 10000\n",
            "max admission num: 94\n",
            "mean admission num: 3.69\n",
            "max code num in an admission: 39\n",
            "mean code num in an admission: 9.23\n",
            "saving parsed data ...\n",
            "saved patient_admission data ...\n",
            "saved admission_codes data ...\n",
            "patient num: 10000\n",
            "max admission num: 71\n",
            "mean admission num: 3.69\n",
            "max code num in an admission: 39\n",
            "mean code num in an admission: 9.32\n",
            "saving parsed data ...\n",
            "saved patient_admission data ...\n",
            "saved admission_codes data ...\n",
            "patient num: 10000\n",
            "max admission num: 52\n",
            "mean admission num: 3.68\n",
            "max code num in an admission: 39\n",
            "mean code num in an admission: 9.26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for idx, seed in enumerate(seeds):\n",
        "#   parsed_path_sample = os.path.join(parsed_path,str(idx))\n",
        "#   patient_admission = pickle.load(open(os.path.join(parsed_path_sample, 'patient_admission.pkl'), 'rb'))\n",
        "#   admission_codes = pickle.load(open(os.path.join(parsed_path_sample, 'admission_codes.pkl'), 'rb'))"
      ],
      "metadata": {
        "id": "p4QpBkwWHqV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -a /content/CHET/data/mimic3/parsed/ /content/drive/MyDrive/CHET/data/mimic3/parsed/\n",
        "!cp -a /content/CHET/data/mimic3/parsed/ /content/drive/MyDrive/CHET/data/mimic3/parsed/"
      ],
      "metadata": {
        "id": "3OJRrYBCdnzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp -a /content/CHET/data/mimic4/parsed/ /content/drive/MyDrive/CHET/data/mimic4/parsed/\n",
        "# !cp -a /content/CHET/data/mimic4/parsed/ /content/drive/MyDrive/CHET/data/mimic4/parsed/"
      ],
      "metadata": {
        "id": "QT376kFsJeva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "codes = list(admission_codes.values())\n",
        "codes = list(set(flatten_list(codes)))\n",
        "tokenizer = Tokenizer(tokens=codes)\n",
        "code_map = tokenizer.vocabulary.token2idx\n",
        "admission_codes_encoded = { admission_id: tokenizer.convert_tokens_to_indices(codes) for admission_id, codes in admission_codes.items() }\n",
        "code_num = len(code_map)\n",
        "print('There are %d codes' % code_num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmxCfXyH03Ry",
        "outputId": "035ca9dd-6e11-46ce-c919-0c16a7a9cb8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2822 codes\n"
          ]
        }
      ]
    }
  ]
}