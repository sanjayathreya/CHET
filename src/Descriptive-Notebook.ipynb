{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNR7/xI6L/DFDTQi255Kzd1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjayathreya/cs598dl4h-project/blob/main/src/Descriptive-Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Reproducibility summary**\n",
        "\n",
        "This notebook describes the methods followed by the paper **Chang Lu, Tian Han, and Yue Ning. 2021a. Context- aware health event prediction via transition functions on dynamic disease graphs(Chet). ArXiv, abs/2112.05195**\n",
        "\n",
        "1.   **Claim 1**: For heart failure prediction task, Chet outperforms the baseline models based on metrics such as **AUC and F1-scores on MIMIC III and MIMIC IV data sets.**\n",
        "\n",
        "2. **Claim 2**: For diagnosis prediction task, Chet outperforms the baseline models based on MIMIC III and MIMIC IV data sets. The authors compare w-F1 is a weighted sum of F1 scores for all medical codes and R@k which is an average ratio of desired medical codes in top k predictions by the total number of desired medical codes in each visit.\n",
        "\n",
        "To verify these claims, we reproduced these results MIMIC III- carevue (Johnson et al., 2022) which excludes overlap of patients in MIMIC IV, and MIMIC IV (Johnson et al., 2023). Additionally, we investigated the effectiveness of the model under different experimental setups such comparing performance of model by changing the number of training epochs, using a different pre-processing\n",
        "method to extract data, ablation studies that do not include dynamic graph and transition functions.\n",
        "\n",
        "***This notebook describes the methods followed on reproducing the paper on [MIMIC III carevue dataset](https://physionet.org/content/mimic3-carevue/1.4/)***\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9lAd4XW2mMUM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial setup"
      ],
      "metadata": {
        "id": "6yvXt0LbmLl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/sanjayathreya/cs598dl4h-project\n",
        "!mv /content/cs598dl4h-project /content/CHET"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4s6ws3xmOw3",
        "outputId": "f7c349ba-dfcb-4b16-e2eb-d197690b89a2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cs598dl4h-project'...\n",
            "remote: Enumerating objects: 326, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 326 (delta 0), reused 1 (delta 0), pack-reused 321\u001b[K\n",
            "Receiving objects: 100% (326/326), 14.61 MiB | 7.24 MiB/s, done.\n",
            "Resolving deltas: 100% (180/180), done.\n",
            "Updating files: 100% (78/78), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Copy the files paitients.csv, admissions.csv and diagnoses_icd.csv to mimic3\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp -a /content/drive/MyDrive/CHET/data/mimic3/raw/ /content/CHET/data/mimic3/\n",
        "!cp -a /content/drive/MyDrive/CHET/data/mimic4/raw/ /content/CHET/data/mimic4/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rybth0xtlxuI",
        "outputId": "3eddca28-95bb-4426-e035-379196e14bd0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/CHET/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LX5dtYwD0a5y",
        "outputId": "8a6d28ab-1ac5-451d-b425-62a161cca1cd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CHET\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "M8Ox1JXkVQ8z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7ca4494-fbc5-47a5-b918-d620df1160a0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.5.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (8.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2022.7.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (1.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (3.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (0.15.1+cu118)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (4.5.0)\n",
            "Collecting pyhealth\n",
            "  Downloading pyhealth-1.1.3-py2.py3-none-any.whl (113 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.8/113.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 11)) (3.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 11)) (3.12.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 11)) (3.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 11)) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 11)) (2.0.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->-r requirements.txt (line 11)) (16.0.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->-r requirements.txt (line 11)) (3.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 13)) (2.27.1)\n",
            "Collecting rdkit>=2022.03.4\n",
            "  Downloading rdkit-2023.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pyhealth->-r requirements.txt (line 15)) (4.65.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 11)) (2.1.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 13)) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 13)) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 13)) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 13)) (2022.12.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 11)) (1.3.0)\n",
            "Installing collected packages: rdkit, pyhealth\n",
            "Successfully installed pyhealth-1.1.3 rdkit-2023.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change working directory to CHET/src"
      ],
      "metadata": {
        "id": "M14L0nwg6oc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/CHET/src\n",
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "lRowZYrvVTl0",
        "outputId": "21f9067b-8da3-463f-c40e-854da2e74266"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CHET/src\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/CHET/src'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing and dataset statistics"
      ],
      "metadata": {
        "id": "Yyw7Ez1d7riJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to preprocess MIMIC4dataset we need to copy over the mapping of ICD10CM to ICD9CM to the cache folder on the containerized colab environment."
      ],
      "metadata": {
        "id": "UvRMSyZT6uHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyhealth.medcode import CrossMap\n",
        "from pyhealth.datasets import MIMIC4Dataset,MIMIC3Dataset\n",
        "!cp /content/CHET/ICD10CM_to_ICD9CM.csv /root/.cache/pyhealth/medcode"
      ],
      "metadata": {
        "id": "m-rsPuT7VXMA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create parsed datasets for MIMIC III Carevue subset and \n"
      ],
      "metadata": {
        "id": "ovKgJHLv7A8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from preprocess import *\n",
        "import os\n",
        "seed = 2000\n",
        "dataset_name = 'mimic3'\n",
        "data_path = os.path.join('..','testing')\n",
        "dataset = dataset_name\n",
        "dataset_path = os.path.join(data_path, dataset)\n",
        "parsed_sample_path = os.path.join(dataset_path, 'parsed')\n",
        "parsed_main_path = os.path.join(data_path, dataset, 'parsed')\n",
        "encoded_path = os.path.join(dataset_path, 'encoded')\n",
        "standard_path = os.path.join(dataset_path, 'standard')\n",
        "\n",
        "\n",
        "patient_admission, admission_codes, ds = generate_parsed_datesets(dataset,parsed_main_path,ret_value=True)\n",
        "df = get_stats_df(patient_admission, admission_codes)\n",
        "df"
      ],
      "metadata": {
        "id": "-EWp7FS0-I4I",
        "outputId": "62f33f7e-7cb3-4476-8ae6-e97d4ef9e8a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   # patients  # maximum visits  average # visits  max # diagnoses codes  \\\n",
              "0        2169                23          2.447211                     39   \n",
              "\n",
              "   avg # diagnoses codes  \n",
              "0              10.702148  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41eed4ab-a97a-4399-866d-6b7c671e5ac4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th># patients</th>\n",
              "      <th># maximum visits</th>\n",
              "      <th>average # visits</th>\n",
              "      <th>max # diagnoses codes</th>\n",
              "      <th>avg # diagnoses codes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2169</td>\n",
              "      <td>23</td>\n",
              "      <td>2.447211</td>\n",
              "      <td>39</td>\n",
              "      <td>10.702148</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41eed4ab-a97a-4399-866d-6b7c671e5ac4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-41eed4ab-a97a-4399-866d-6b7c671e5ac4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-41eed4ab-a97a-4399-866d-6b7c671e5ac4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Tasks"
      ],
      "metadata": {
        "id": "AIFlZFxeRkqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1**: Use Tokenizer object in pyhealth to encode admission codes"
      ],
      "metadata": {
        "id": "glcOFDJxSXyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  max_admission_num = get_stats(patient_admission, admission_codes)\n",
        "\n",
        "  # Generate code map and encode admission_codes\n",
        "  codes = list(admission_codes.values())\n",
        "  codes = list(set(flatten_list(codes)))\n",
        "  tokenizer = Tokenizer(tokens=codes)\n",
        "  code_map = tokenizer.vocabulary.token2idx\n",
        "  admission_codes_encoded = { admission_id: list(set(tokenizer.convert_tokens_to_indices(codes))) for admission_id, codes in admission_codes.items() }\n",
        "  code_num = len(code_map)\n",
        "  print('There are %d codes' % code_num)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6xkvwvpxRBYB",
        "outputId": "9978fea2-31fd-4a07-e99c-99ec95fb64a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "patient num: 2169\n",
            "max admission num: 23\n",
            "mean admission num: 2.45\n",
            "max code num in an admission: 39\n",
            "mean code num in an admission: 10.70\n",
            "There are 2821 codes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2**: Generate code levels. In this step we take the diagnoses codes for all admissions encode them into a 3 level hierarchy. This hiearchy is derived using ancestoral relationship in pyhealth. Where there are more than 3 levels , we force the hierarchy to three levels. The approach is similar to the one followed by the authors of the paper."
      ],
      "metadata": {
        "id": "chBBAigvTrDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# diagnosis code levels\n",
        "code_levels = generate_code_levels(code_map)\n",
        "print(\"\\ncompleted code levels\")\n",
        "code_levels[:2]"
      ],
      "metadata": {
        "id": "zXCqGSLGTqD0",
        "outputId": "56283b0e-30b8-45c4-bb4b-59f7d71638eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "generating code level matrix for codes: 100%|██████████| 2821/2821 [00:00<00:00, 7702.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "completed code levels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 15, 120,  88,   0],\n",
              "       [ 18, 179, 818,   1]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step3**: Split patients into Train , validation and test datasets. \n",
        "\n",
        "While performing the split , we ensure that all diagnoses codes are seen in the training set and the admission with maximum number of diagnosis codes are also included. The reason is to ensure no unseen codes in testing and ensure no out of memory exceptions during testing.\n",
        "\n",
        "After this step we save all encoded datasets to encoded folder for further processing."
      ],
      "metadata": {
        "id": "ldu9lhloUjnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset to train , validation, test 80/10/10\n",
        "train_pids, valid_pids, test_pids  = split_patients(patient_admission, admission_codes, code_map, ratios=(.80,.10,.10), seed=seed)\n",
        "all_pids = { 'train_pids': train_pids, 'valid_pids': valid_pids, 'test_pids': test_pids }\n",
        "save_files(encoded_path, patient_admission =patient_admission, codes_encoded=admission_codes_encoded, code_map = code_map, pids = all_pids)"
      ],
      "metadata": {
        "id": "iFFbItPAUdUI",
        "outputId": "8aefc665-8b0a-4359-e448-5b951d4e0a59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Split Paitents: 100%|██████████| 2821/2821 [00:00<00:00, 265009.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split patient_admission #: 2169 into \n",
            "\t Train #: 1735 \n",
            "\t Validation #: 218 \n",
            "\t Test #: 216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step5**: In this step, we generate the code code adjacency matrix   \n",
        "\n",
        "If a diagnosis code pair $(c_i, c_j)$, co-occurred in patients visit then , two edges with $\\overrightarrow{(i,j)}$ and $\\overleftarrow{(i,j)}$  are recorded. These are asymmetric because the authors surmise that two diseases may not have equal influence on each other. $f_{ij}$ is the total co-occurrence frequency $(c_i, c_j)$ for \\textbf{all} patient visits. In order to detect important disease relationships, they filter out combinations with low frequency. $\\Delta_i = {c_j | \n",
        "\\frac{f_{ij}}{\\sum_{j=1}^{d}f_{ij}} \\geq \\delta}$. This is stored in adjacency matrix $\\mathcal{A}$ which is static and measures global co-occurrence frequencies of diseases."
      ],
      "metadata": {
        "id": "Rcns-zzJVz3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate global adjacency matrix\n",
        "adj_matrix = generate_code_code_adjacent(train_pids, patient_admission, admission_codes_encoded, code_num, threshold=0.01)\n",
        "norm_adj_matrix = normalize_adj(adj_matrix)\n",
        "save_dict = {'code_adj': norm_adj_matrix}\n",
        "save_files(standard_path, type='standard', **save_dict)"
      ],
      "metadata": {
        "id": "J13ocz5MVy2M",
        "outputId": "0010bb55-2b2a-4a36-f176-e45aeacf2a33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "generating global code code adjacent matrix: 100%|██████████| 1735/1735 [00:00<00:00, 4022.65it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-5c241ddcb729>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnorm_adj_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_adj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msave_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'code_adj'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnorm_adj_matrix\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msave_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstandard_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'standard'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msave_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'standard_path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7N7LF-kVWlpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate all datasets\n",
        "datasets = ['train', 'valid', 'test' ]\n",
        "for idx, dataset in enumerate(datasets):\n",
        "  if dataset == 'train':\n",
        "    pids = train_pids\n",
        "  elif dataset == 'valid':\n",
        "    pids = valid_pids\n",
        "  else:\n",
        "    pids = test_pids\n",
        "  print(f'\\nprocessing standard data for {dataset}\\n')\n",
        "  (X, Y, visit_lens) = construct_x_y(pids, patient_admission, admission_codes_encoded, max_admission_num, code_num)\n",
        "  N_t = build_neighbor_codes(X, visit_lens, adj_matrix)\n",
        "  M_t = divide_disease_type_matrices(X, N_t, visit_lens)\n",
        "  Y_hf = construct_hf_label_y(Y, code_map)"
      ],
      "metadata": {
        "id": "LylfWg1oWmZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Eb1iwHU4Wqkn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}